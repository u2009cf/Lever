\section{System Design}

  In this section, we describe the design of Lever. Lever is designed to be API-compatible with Spark Streaming, providing the mitigation transparency and developer transparency. Considering the main objective is to lower latency, Lever is lightweight. We begin with an overview of the system architecture, followed by introducing the system details.

\subsection{System Overview}

  Figure 4 overviews the architecture of Lever. Lever periodically collects and analyzes the historical jobs' profiles of recurring batched streaming jobs. Based on these analysis, Lever pre-schedules job input data through three main steps, i.e. identify potential stragglers, evaluate nodes' capability and choose suitable helpers. Firstly, comparing each node's task finish time in previous batch, Lever can initially determine initial state of each node. Lever also estimates the changes of input data rate. Combined with these two aspects, Lever conduct state transition to decide which nodes will behaviors as stragglers in next batch(for Challenge 1). Secondly, based on the fact that batched stream processing jobs are repetitive and periodic, Lever introduces Iterative Learning Control (ILC \cite{Arimoto}), which is designed to do tracking control for systems that work in a repetitive mode to learn to estimate node's capability (for Challenge 2). Finally, considering that Lever don't have resource utilization view when pre-scheduling, Lever can choose all nodes or two least load nodes as helpers. Lever can adaptively switch between these two strategies to pursue high performance(for Challenge 3).

  We show the actions timing diagram of Lever in Figure 5, where we differentiate pre-scheduling and post-scheduling according to their scheduling timing. It can be seen that post-scheduling (e.g., Dolly, Wrangler, Speculation\&SkewTune) acts during processing but Lever, as a pre-scheduling approach, acts before task scheduling. As shown in Figure 5, Lever collects the needed information of the previous job's execution during batch interval between $t_1$ and $t_2$.
  Then, during $t_2$ and $t_3$, Lever pre-schedules input data based on prior pre-scheduling plan. When come to batch $t_3$ to $t_4$, Lever schedules tasks according to data locality as usual. We detail each step of Lever in the following.
  \begin{figure*}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{FigureAction}
    \caption{Actions of Lever}
    \label{Fig. 5:}
  \end{figure*}

\subsection{Identify Potential Stragglers}

  Lever predicts stragglers in the next batch according to recurring jobs' historical execution information combined with the load fluctuation of each node. The first step is to determine the initial stragglers. When last batch's jobs are completed, Lever collects and analyze the statistics of tasks' execution information in each node. The node i's finish time ($NFT_i$) is defined as the time from job's submission to the last task finish in this node. Then, Lever sorts node's list according to $NFT_i$ in the descending order. It classify nodes into three categories according to two locations 0.25, 0.75(we refer to the quantile of speculation \cite{Dean2004}) of node's list size. Nodes before 0.25$\times$size are grouped into \emph{straggler group}. Nodes after 0.75$\times$size are grouped into \emph{faster group}. The remaining are categorized as \emph{median group}.

  This classification can only represent the stragglers in the last batch. Because stream load varies over time, i.e., load fluctuation, the state of each node may be different between two consecutive jobs. Therefore, we shall carefully derive the possible state transitions to accurately identify the stragglers as follows. First, Lever calculates the median finish time of \emph{straggler group}, \emph{median group} and \emph{faster group} respectively, represented as \emph{FTOS}, \emph{FTOM}, \emph{FTOF}. Second, Lever introduces degradation ratio \emph{FTM} and \emph{MTS}. \emph{FTM} is defined as \emph{FTOM}/\emph{FTOF}. It means that if one node's $NFT_i$ in \emph{faster group} has increased by FTM, it will be moved from \emph{faster group} to \emph{median group} and vice versa. Similarly, \emph{MTS} is defined as \emph{FTOS}/\emph{FTOM}. It means that if one node's $NFT_i$ in \emph{median group} has increased by MTS, it will be moved from \emph{median group} to \emph{straggler group} and vice versa. We have shown straggler's state transition in Fig. 6.
  \begin{figure}[htbp]
    \centering
    \includegraphics[width=0.42\textwidth]{FigureI2}
    \caption{An example for straggler's state transition}
    \label{Fig. 6:}
  \end{figure}

  Based on the transition graph in Fig. 6, in the third step, Lever takes the load fluctuation observed on each node to conduct state transition for straggler identification. Due to the load fluctuation, last batch's stragglers may receive less data and hence become faster in current batch. Similarly, the faster nodes may also possibly becom stragglers in current batch. Lever introduces \emph{inputRatio} as the ratio between the new input data rate of current batch and the old one of the last batch to evaluate the changes of stream load. According to the transition graph, we define the transition rules in Table \uppercase\expandafter{\romannumeral1}, by applying which Lever finally identifies the state of each node for current batch.
  \begin{table}[htbp]
    \footnotesize
    \centering
    \caption{Transition rules for identifying stragglers}
    \begin{threeparttable}
    \centering
      \begin{tabular}{|p{1.5cm}|p{4.3cm}|p{1.4cm}|}
        \hline
        Initial State & Transition Conditions(inputRatio) & Final State \\
        \hline
        \multirow{3}{2cm}{Straggler} &
        (1/MTS,$+\infty$) & Straggler \\
        \cline{2-3}
        & [1/(FTM*MTS),1/MTS] & Median \\
        \cline{2-3}
        & (0,1/(FTM*MTS)) & Faster \\
        \hline
        \multirow{3}{2cm}{Median} &
        (MTS,$+\infty$) & Straggler \\
        \cline{2-3}
        & [1/FTM,MTS] & Median \\
        \cline{2-3}
        & (0,1/FTM) & Faster \\
        \hline
        \multirow{3}{2cm}{Faster} &
        (FTM*MTS,$+\infty$) & Straggler \\
        \cline{2-3}
        & [FTM,FTM*MTS] & Median \\
        \cline{2-3}
        & (0,FTM) & Faster \\
        \hline
      \end{tabular}
    \end{threeparttable}
    \label{Table1}
  \end{table}

\subsection{Computational Capability Determination}

  After determine the state of each node according to the input data characteristics, we next evaluate each node's computational capability so as to conduct pre-scheduling, as detailed in this section.

\subsubsection{Computational Capability}

  The computational capability is defined as the metric which one node can process how much data in one batch. As shown in Section \uppercase\expandafter{\romannumeral2}-C, recurring batched stream jobs have stable data properties. By analyzing the previous execution, We can assess these metrics exactly in the subsequent execution.

  Considering the periodicity of recurring batched stream jobs, we evaluate computational capability based on a well-known optimization technique, Iterative Learning Control (ILC \cite{Arimoto}), which is designed to do tracking control for systems that work in a repetitive mode. Repetition allows the system to improve tracking accuracy from repetition to repetition. This learning process uses information from previous repetitions to improve the estimation ultimately enabling a more and more accurate result can be found iteratively. This scenario is similar to batched stream processing jobs.
  \begin{figure}[htbp]
    \centering
    \includegraphics[width=0.36\textwidth]{FigureILC}
    \caption{The principle of evaluating computational capability with ILC.}
    \label{Fig. 7:}
  \end{figure}

  Fig. 7 shows the principle of ILC algorithm. Our objective is to continuously approximate the real computational capability. The task finish time of each node and computational capability in previous batch is passed to ILC model as learning parameter. ILC model uses the control law to compute next batch's computational capability. These actions repeat from one job to next job. A simple control law for one node is of the following form:
  \begin{equation}
  C_{i+1} = C_i + K*\Delta t
  \end{equation}
   \begin{equation}
  \Delta t = t_{ideal} - t_{i}
  \end{equation}
  where $C_i$ is the input capability to the stream processing system during the ith batch, $\Delta t$ is the deviation between node's finish time and ideal finish time during the ith batch. K is a design parameter representing operations on $\Delta t$. In Lever, K is set to $C_i/t_i$. $t_{ideal}$ is the ideal node's finish time in the ith batch and can be got by computing the median node's finish time. We repeat this process one batch by one batch.

\subsubsection{Theoretical Data Assignment}

  In the ideal case, every task should be completed simultaneously. The system should increase the amount of load in faster node and decrease those in straggler to minimize the makespan. Assume that there are n nodes, Let \emph{$L_i$} and \emph{$C_i$} denote the input load and the computational capability of node i respectively. Let \emph{$L_i^\prime$} denote the input load after been tweaked. Let $t_i$ denote the finish time of node i. So we have:
  \begin{equation}
  t_i = L_i\prime / C_i
  \end{equation}
  \begin{equation}
  \sum_{i=1}^n L_i = \sum_{i=1}^n L_i\prime
  \end{equation}
  In the ideal case, our optimization goal is $\delta^{2}=D(t_i)=0$. So, we have $t_1=t_2=...=t_n$. Then, we can get $L_1\prime/C_1=L_2\prime/C_2=...=L_n\prime/C_n$. The load \emph{$L_i^\prime$} after been tweaked can be denoted as:
  \begin{equation}
  L_i\prime =  \frac{\sum_{i=1}^n L_i}{\sum_{i=1}^n C_i}*C_i
  \end{equation}
  So, the load we need to migrate to or from can be denoted as:
  \begin{equation}
  \Delta L = L_i\prime - L_i = \frac{\sum_{i=1}^n L_i}{\sum_{i=1}^n C_i}*C_i - L_i
  \end{equation}

\subsection{Choose Suitable Helpers and Reassign Work}

  As we have grouped all workers into three groups, the nodes in faster group are eligible to perform as helpers to afford a portion of stragglers' workload. Nodes in straggler group are helpee to whom workers are eligible to provide assistance. There are two situations Lever is faced with in real production clusters. One is that there are few stragglers and few fasters. On the contrary, another is that there are many stragglers and many fasters. The overhead for partition and migration varies in different situations. To this end, we propose two helper choosing strategies and adaptively adopt one of them according to the on-site situation.

\subsubsection{Strategies for Choosing Helpers}

  \textbf{All Strategy.} With this strategy, all nodes in faster group are selected as candidate helpers. According to Section \uppercase\expandafter{\romannumeral3}-C, we can obtain the relatively ideal load distribution by the proportion of node's capability. Fig.8 shows the principle of all strategy. Assume that we have n helpers which ith helper is represented by the vector (\emph{$C_i$},\emph{$L_i$}) and stragglers are the same. For each straggler with (\emph{$C_s$},\emph{$L_s$}), its input data is assigned to those selected helpers according to each node's capability and load. The load share \emph{{$L_{sToj}$}} which is dispatched to jth helper can be denoted as:
  \begin{equation}
  L_{sToj} = \frac{L_s + \sum_{i=1}^n L_i}{C_s + \sum_{i=1}^n C_i}*C_j - L_j
  \end{equation}

  This strategy is suitable for the situation that there are few stragglers and fasters. However, if there are large number of stragglers and fasters, the overhead of partition and migration can't be ignored.
  \begin{figure}[htbp]
    \centering
    \includegraphics[width=0.48\textwidth]{FigureS1}
    \caption{All Strategy selects all nodes in faster group as helpers.}
    \label{Fig. 8:}
  \end{figure}

  \textbf{Two Choice Strategy.} Different from all strategy, two choice strategy chooses two nodes in faster group as helpers. Lever refers to the power of two choice\cite{Mitzenmacher1996} and intends to find out two nodes which have the large computational capability meanwhile have much less input data load as helpers. Fig. 9 shows the principle of two choice strategy. First, Lever sorts the nodes' list according to each node's \emph{$C_i$}/\emph{$L_i$} in the descending order. Then, Lever chooses the head two nodes as helpers and computes load share for each helper. Assume that the two selected helpers are $(C_1, L_1)$ and $(C_2, L_2)$, the straggler can be represented as (\emph{$C_s$},\emph{$L_s$}). The load share \emph{{$L_{sToj}$}} which is dispatched to jth helper can be denoted as:
  \begin{equation}
  L_{sToj} = \frac{L_s + L_1 + L_2}{C_s + C_1 + C_2}*C_j - L_j
  \end{equation}
  After reassignment, Lever updates each node's $C_i$ and $L_i$.
  \begin{figure}[htbp]
    \centering
    \includegraphics[width=0.48\textwidth]{FigureS2}
    \caption{Two Choice Strategy selects two nodes in faster group as helpers.}
    \label{Fig. 9:}
  \end{figure}

\subsubsection{Adaptively Choose One of Two}

  The above two strategies can be used in different situations. Lever can adaptively choose one of two strategies according to cluster's current state. Obviously, when there are few stragglers, all strategy is much better than two choice strategy because we can pre-schedule input data as evenly as possible. However, if there are large numbers of stragglers and fasters, two choice strategy will behavior better because of avoiding heavy blocks partition and migration. For example, if we have s stragglers and t fasters, this strategy will produce $s*t$ data pieces and also $s*t$ socket collections. Huge amount of $s*t$ value will incur network congestion and impact current jobs' execution.

  Lever combines the latency changes with the \#stragglers$\times$\#fasters to make adaptive choice. If \#stragglers$\times$\#fasters is larger than a observed value, Lever should select two choice strategy. Also another case is that when we detect that the latency of Lever is increasing after we adopt all strategy, then we will switch to two choice strategy. The complete pseudo code of pre-scheduling algorithm is presented in Algorithm 1.
  \begin{algorithm}[htbp]
  \small
  \caption{Pre-Scheduling Algorithm}
  \label{Alg:1}
  \begin{algorithmic}[1]
  \STATE \textbf{Procedure} \textbf{Identify Potential Stragglers}
  \STATE \quad Get the previous batches' job execution information
  \STATE \quad Sort the nodes descending by their finish time
  \STATE \quad Group the nodes into three groups(straggler, median, faster)
  \STATE \quad Compute the input load's gradient
  \STATE \quad Transform nodes' state according to transition rules
  \STATE \quad Output final stragglers and fasters
  \STATE \textbf{End Procedure}
  \STATE \textbf{Procedure} \textbf{Evaluate Computational Capability}
  \STATE \quad In ith batch, compute i+1th batch's capability
  \STATE \quad $C_{i+1} = C_i + C_i/t_i*(t_{ideal}-t_i)$
  \STATE \quad Assign corresponding load when receiving i+1th batch's data
  \STATE \quad In i+1th batch, compute the next batch's capability
  \STATE \quad $C_{i+2} = C_{i+1} + \frac{C_{i+1}}{t_{i+1}}*(t_{ideal}-t_{i+1})$
  \STATE \textbf{End Procedure}
  \STATE \textbf{Procedure} \textbf{Choose Suitable Helpers and Reassign Work}
  \IF{(\#stragglers$\times$\#fasters$<$$\rho$) or (last batch use AllStrategy \&\& latency decreases)}
  \STATE $/*$ continue to adopt allstrategy $*/$
  \STATE Choose all the nodes as helpers
  \STATE Compute the sum of helpers' capability and the sum of helpers' load
  \STATE $sumOfCapa=\sum_{i=1}^n C_i$ and $sumOfLoad=\sum_{i=1}^n L_i$
  \FOR{each straggler node}
  \FOR{each helper node}
  \STATE Compute the allocated load share
  \STATE $L_{stoi}=\frac{L_s + sumOfLoad}{C_s + sumOfCapa}\times C_i-L_i$
  \STATE Update each node's $(C_i,L_i)$
  \ENDFOR
  \ENDFOR
  \ELSE
  \STATE $/*$ adopt TwoChoiceStrategy $*/$
  \STATE Sort the nodes' list according to each node's $\frac{C_i}{L_i}$ in the descending order
  \STATE Choose the head two nodes as helpers
  \STATE Compute the sum of helpers' capability and the sum of helpers' load
  \STATE $sumOfCapa = C_1 + C_2$ and $sumOfLoad = L_1 + L_2$
  \FOR{each straggler node}
  \FOR{each helper node}
  \STATE Compute the allocated load share
  \STATE $L_{stoi}=\frac{L_s + sumOfLoad}{C_s + sumOfCapa}\times C_i-L_i$
  \STATE Update each node's $(C_i,L_i)$
  \ENDFOR
  \ENDFOR
  \ENDIF
  \STATE \textbf{End Procedure}
  \end{algorithmic}
  \end{algorithm}